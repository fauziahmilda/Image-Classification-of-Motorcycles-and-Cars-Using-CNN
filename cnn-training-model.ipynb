{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine iteration/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "DEV = False\n",
    "argvs = sys.argv\n",
    "argc = len(argvs)\n",
    "\n",
    "if argc > 1 and (argvs[1] == \"--development\" or argvs[1] == \"-d\"):\n",
    "    DEV = True\n",
    "if DEV:\n",
    "    epochs = 2\n",
    "else:\n",
    "    epochs = 30\n",
    "\n",
    "train_data_path = 'data\\kendaraan'\n",
    "validation_data_path = 'data\\percobaan'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "samples_per_epoch = 1000\n",
    "validation_steps = 300\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "pool_size = 2\n",
    "classes_num = 2\n",
    "lr = 0.0004"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, activation='relu', padding ='same', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, conv2_size, activation='relu', padding ='same'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), strides=1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes_num, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=lr),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 470 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zia\\AppData\\Local\\Temp\\ipykernel_7960\\3742505317.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  15/1000 [..............................] - ETA: 5:00 - loss: 0.9535 - accuracy: 0.5191WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30000 batches). You may need to use the repeat() function when building your dataset.\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.9535 - accuracy: 0.5191\n",
      "Execution Time: 21.69673466682434 seconds\n"
     ]
    }
   ],
   "source": [
    "log_dir = './tf-log/'\n",
    "tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "cbks = [tb_cb]\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=samples_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=cbks,\n",
    "    validation_steps=validation_steps)\n",
    "\n",
    "target_dir = './models/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "model.save('./models/model.h5')\n",
    "model.save_weights('./models/weights.h5')\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "    print(\"Execution Time:\",dur,\"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
